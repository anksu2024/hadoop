package com.cloudwick.hadoop.JobChaining;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class Mapper2 extends Mapper<IntWritable, Text, Text, Text> {
	@Override
	protected void map(IntWritable key, Text value,
			Mapper<Text, Text, Text, Text>.Context context)
			throws IOException, InterruptedException {
		String parts[] = value.toString().split(",");

		int salary = Integer.parseInt(parts[2].trim());
		if (salary >= 100000 && salary <= 130000) {
			context.write(value, new Text());
		}
	}
}